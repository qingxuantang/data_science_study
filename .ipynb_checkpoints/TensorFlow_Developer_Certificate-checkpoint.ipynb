{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Developer Certificate @ Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此 notebook 用于存储和练习 TensorFlow Developer Certificate 课程相关内容<br>\n",
    "https://www.coursera.org/professional-certificates/tensorflow-in-practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最简单的 neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 32.7426\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 26.0851\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.8406\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.7079\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.4502\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8808\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8533\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2521\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9864\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9849\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1913\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5614\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.0605\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6610\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3415\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0851\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8783\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7108\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5742\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4620\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3692\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2916\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2262\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1705\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1224\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0804\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0433\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0101\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.980 - 0s 4ms/step - loss: 0.9802\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9528\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9275\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9040\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8819\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8610\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8411\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8221\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8039\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7863\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7693\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7528\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7369\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7213\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7062\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6914\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6770\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6630\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6492\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6358\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6227\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6098\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5972\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5849\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5729\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5611\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5495\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5382\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5272\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5163\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5057\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4953\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4852\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4752\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4654\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4559\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4465\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4373\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4283\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4195\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4109\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4025\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3942\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3861\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3782\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3704\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3628\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3554\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3481\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3409\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3339\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3270\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3203\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3137\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3073\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3010\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2948\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2888\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2828\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2770\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2713\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2657\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2603\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2549\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2497\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2446\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2396\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2346\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2298\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2251\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2205\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2159\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2115\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2072\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2029\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1987\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1947\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1907\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1829\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1791\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1755\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1719\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1683\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1649\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1615\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1582\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1549\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1517\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1486\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1456\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1426\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1397\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1368\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1340\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1312\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1285\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1259\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1233\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1208\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1183\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1159\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1135\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1111\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1089\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1044\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1023\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1002\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0981\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0961\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0941\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0922\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0903\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0885\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0866\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0849\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0831\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0814\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0797\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0781\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0765\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0749\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0734\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0719\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0704\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0690\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0675\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0662\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0648\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0635\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0609\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0596\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0584\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0572\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0560\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0549\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0538\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0527\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0516\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0505\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0495\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0485\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0475\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0465\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0455\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0446\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0437\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0428\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0410\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0402\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0394\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0386\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0378\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0370\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0362\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0355\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0348\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0341\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0334\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0327\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0320\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0313\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0307\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0301\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0294\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0288\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0282\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0277\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0271\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0265\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0260\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0255\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0249\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0244\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0239\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0234\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0230\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0225\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0220\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0216\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0211\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0203\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0194\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0190\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0187\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0179\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0158\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0155\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0139\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0134\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0131\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0128\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0126\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0123\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0121\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0118\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0116\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0113\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0111\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0109\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0107\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0104\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0100\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0098\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0090\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0087\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0083\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0072\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0067\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0066\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0065\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0060\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0058\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0053\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0049\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0037\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0036\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0033\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0033\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0017\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9959e-04\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7906e-04\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5895e-04\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.3925e-04\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1996e-04\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0107e-04\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8256e-04\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6443e-04\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.4667e-04\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.2928e-04\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1224e-04\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9556e-04\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7922e-04\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.6321e-04\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4754e-04\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3218e-04\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1714e-04\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0241e-04\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8798e-04\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7385e-04\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6001e-04\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4645e-04\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3317e-04\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2017e-04\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0743e-04\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9495e-04\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8273e-04\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7077e-04\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5904e-04\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4756e-04\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3631e-04\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2529e-04\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1450e-04\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.0394e-04\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.9358e-04\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8345e-04\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7352e-04\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6379e-04\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5426e-04\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4493e-04\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.3579e-04\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2684e-04\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1807e-04\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0948e-04\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0107e-04\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9284e-04\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8477e-04\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7686e-04\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6912e-04\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6154e-04\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5411e-04\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4684e-04\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3971e-04\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3274e-04\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2590e-04\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1921e-04\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1265e-04\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0623e-04\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9994e-04\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9378e-0 - 0s 2ms/step - loss: 2.9378e-04\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8774e-04\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8183e-04\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7605e-04\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7037e-04\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6482e-04\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5938e-04\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5405e-04\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4883e-04\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4372e-04\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3872e-04\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3381e-04\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2901e-04\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2431e-04\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1970e-04\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1519e-04\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1077e-04\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0644e-04\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0219e-04\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9804e-04\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9397e-04\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8999e-04\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8609e-04\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8226e-04\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7852e-04\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7485e-04\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7126e-04\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6774e-04\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6430e-04\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6092e-04\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5762e-04\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5438e-04\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5121e-04\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4811e-04\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4506e-04\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4208e-04\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3917e-04\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3631e-04\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3351e-04\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3076e-04\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2808e-04\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2545e-04\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2287e-04\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2035e-04\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1787e-04\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1545e-04\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1308e-04\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1076e-04\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0848e-04\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0625e-04\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0407e-04\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0193e-04\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9840e-05\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7788e-05\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5779e-05\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3813e-05\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1887e-05\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.9998e-05\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8149e-05\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.6339e-05\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4567e-05\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.2829e-05\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.1128e-05\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9460e-05\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7829e-05\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6230e-05\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4665e-05\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3130e-05\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1628e-05\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0157e-05\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8716e-05\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7304e-05\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5923e-05\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4568e-05\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3241e-05\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1943e-05\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0670e-05\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.9425e-05\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8204e-05\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7008e-05\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.5837e-05\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4691e-05\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3567e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe62e501780>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.array([-1.0,0.0,1.0,2.0,3.0,4.0],dtype=float)\n",
    "ys = np.array([-3.0,-1.0,1.0,3.0,5.0,7.0],dtype=float)\n",
    "#最简单的neural net，一个layer，一个unit（也就是一个neuron）\n",
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "# sgd = stochastic gradient descent\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "model.fit(xs,ys,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.978647]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单的 computer vision 神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  32  60   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  85 216 144  43\n",
      "    0   0   0   0   0   0   0  91  54   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0  27 172 200 182 189 197\n",
      "    0   0   0  12 110 130 139 127  66   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3   0  45 212 180 158 213 235\n",
      "   92  27 103 184 193 132  43   0   0   0]\n",
      " [  0   0   0   0   0   0   2   1   0   0   0   0   0 194 222 163 163 182\n",
      "  239 211 164  69  25   0   0   1   5   0]\n",
      " [  0   0   0   0   2   0   0   0   0   0   0   0   0  55 244 242 229 200\n",
      "  216  63   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   1   0   0  24 117 190   0   0   0   0   0 157 230 226 202\n",
      "  206 148   0   0   3  18  30  39  65  48]\n",
      " [  1   2   1   1   0 144 197 184 206 150   0   0   0   0   5  94 157 189\n",
      "  203 243 177 108 136 149 154 150 145 108]\n",
      " [  0   0   0   0   0 101 235 197 171 230  30   0   0   0   0  47 200 206\n",
      "  148 154 109  75  54  61  61  57  75  54]\n",
      " [  6  16   1   0   0   0 190 126   0 200 101   0  29  85 119 127 154 101\n",
      "   90  97  66 118 105 121  91  94 122  48]\n",
      " [ 41 112 113 115 106  94 197 206 114 194 255 119 123 118  79  86  55 108\n",
      "   74  74  81  57 103  54  82  86  83  46]\n",
      " [ 29  72  34  74  59  83 100  63  96  83 114  64  70  63 100  69 100  91\n",
      "   81  87  92  94  87 115  68  70  96  24]\n",
      " [ 20  99  90 104  86 103  82  91  48  78  64 109  92  79  74  95 108  91\n",
      "   88  95  97  75  79 100  92  96  97  14]\n",
      " [  6  97  75  91  79  90  63  94  90  91 100  72  75  83  81  79  55  73\n",
      "   48  88  81  83  68  61  69  39  79   2]\n",
      " [  0  82 115 109 109 123  78  95  92  91 105  90 110 117 130 132 137 141\n",
      "  142 128 126 151 180 170 163 162 114   0]\n",
      " [  0   0   2  39  63  85 112 101 109 105  90  94  77  59  47  43  19   2\n",
      "    0   0   0   3  25  20  27  24   9   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[12])\n",
    "# image的pixel数值范围是 0，255\n",
    "print(train_labels[12])\n",
    "print(train_images[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "[\n",
    "    #第一层layer，使用Flatten把一个个28*28 pixel的图片数据变成线性数值\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    #第二层就是hidden layer，里面的数值代表neuron数量\n",
    "    keras.layers.Dense(1024,activation=tf.nn.relu),\n",
    "    #第三层layer，数值10表示数据库中输出的图片有10个类别（比如靴子，T恤，裤子等等）\n",
    "    keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4703\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3584\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3188\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2954\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe58d0cae10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(#optimizer=tf.train.AdamOptimizer(), #这一行是v1版本中的代码\n",
    "             #optimizer=tf.optimizers.Adam(), #v2版本可用\n",
    "             optimizer = 'Adam',\n",
    "             loss = 'sparse_categorical_crossentropy'\n",
    "             )\n",
    "model.fit(train_images,train_labels,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32938075065612793"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4223087e-07 5.5423164e-09 8.4919890e-08 2.9905627e-09 2.9066207e-08\n",
      " 5.2441115e-04 2.6461586e-07 1.6386388e-02 3.9798568e-08 9.8308867e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9905627e-09, 5.5423164e-09, 2.9066207e-08, 3.9798568e-08,\n",
       "       8.4919890e-08, 1.4223087e-07, 2.6461586e-07, 5.2441115e-04,\n",
       "       1.6386388e-02, 9.8308867e-01], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(classifications[0],axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4695\n",
      "Epoch 2/5\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.3595\n",
      "已经达到60%准确率，训练取消。\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe572727fd0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs = {}):\n",
    "        if logs.get('loss') < 0.4:\n",
    "            print('\\n已经达到60%准确率，训练取消。')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs = 5, callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2006 - accuracy: 0.9407: 0s - loss: 0.208\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0804 - accuracy: 0.9753\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0532 - accuracy: 0.9832\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0366 - accuracy: 0.9881\n",
      "Epoch 5/10\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9917\n",
      "Reached 99% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0267 - accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], 0.9917500019073486)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_mnist():\n",
    "\n",
    "    # YOUR CODE\n",
    "    import tensorflow as tf\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            #if(logs.get('acc')>0.99): #此处的 'acc' 适用于 tensorflow 1.x\n",
    "            if(logs.get('accuracy')>0.99): # 'accuracy' 适用于 tensorflow 2.x\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "    #return history.epoch, history.history['acc'][-1]\n",
    "    return history.epoch, history.history['accuracy'][-1] # 同理 acc对应1.x版本；accuracy对应2.x版本\n",
    "\n",
    "train_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络 convolution nn 和 pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "  52/1875 [..............................] - ETA: 1:14 - loss: 1.3330 - accuracy: 0.5300"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-cab8faa50edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "#因为使用了卷积，所以此处要对数据进行reshape，下同\n",
    "training_images=training_images.reshape(60000,28,28,1)\n",
    "training_images=training_images/255.0\n",
    "#因为使用了卷积，所以此处要对数据进行reshape\n",
    "test_images=test_images.reshape(10000,28,28,1)\n",
    "test_images=test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # 64意味着使用64个filter，每个filter是3*3的大小。input_shape最后一个数1代表数据的color depth是1，因为都是灰度图片\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "    \n",
    "]\n",
    ")\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD7CAYAAAC2a1UBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2de7hcZXXwf+vckpOTQG4mhCQQFIoELBBpBAEbBbmJQKti8FK0tGjRflDto9F+FWvrYyqtD4pYoErBr1wSBSRaUMMlIhcjIYRLQMilCUnIjSQkJ+ecnJzL+v7Ye2b2mf3OzN4ze+7r9zx5zp41797vmpWZ97retURVMQzDMGqLlmorYBiGYYSxxtkwDKMGscbZMAyjBrHG2TAMowaxxtkwDKMGscbZMAyjBimpcRaR80TkFRFZKyILklLKMAyj2Sm6cRaRVuBG4HxgNnCZiMxOSjHDOj/DaGbaSrh3LrBWVdcDiMjdwMXAS7luEJFmP/Hyhqq+JUrBQOf3fmAz8LSILFFVp33NttFtC17HB3wXaAV+qKoL85dvUaG1RBXLjeSQu74aOco6xKpDqA7lenjJVM62ZfsIJaEMOL+7pTTO04FNgdebgXcVvq3Wv+DlZGhjjMKxOz+zbTTidnwAQittbZNLV7OM5GrglKHIZUXCk+mDg9tKU6wAlbJtrXauBwe3OL+7Zd8QFJErRWSFiKwod10Nhqvzm14lXRqNdMenqgeBVMdnGDVDKY3zFmBm4PUMXzYCVb1FVU9R1VNKqMtwYB1f0UTq+IL2VYYrply9Y3slyVBK4/w0cIyIHCUiHcB8YEkyahlE6Pys4ysvQfuKeZ1GwhwFkqPob5yqDgKfB34FvAwsVtXVSSlmWOdXRiLN+oyisCWjhChlQxBVfQB4ICFdjACqOigiqc6vFbjVOr/ESHd8eI3yfOBj1VIm10bVsA445UNDe51yZTBynW2tE9xvOBw7YoYVLtJRwMimpMbZKC/W+ZUH6/iqj4hcCVzpvbIlIxfWOBtNiXV8ZSOyowBwC0CLtDe7j74T67IMw0gS2ytJCBs5GzVNS8u4kGzcqJkh2d6+FyqhjlEAWzJKDmucDcNIFFsySgZrnBMmNdILju729uU5cW00DXGPD7dIu1M+GMMrIxeDQ3tilA4f/zbKjzXOhmFUGYndcbligBSiReI1d30HX4tdR5LYhqBhGEYN0pQjZ28T2ePk0R8GYJKMTcuW9t5S9LOHh7sBuGL8vLTsO020rDGnM3yW499P2h+SvfepaBv4x40+JyQ799CpIdl3bEPQaDBs5GwYhlGDNOXI2Tvy77FBPC+ffz/xyLTspNeuAuC6LT+I9Lzjx3wofb269x4AXtyb2bQ5o/MvAXi87z+L1NioVeKsleZaJ821Fto/GGfTzmg0bORsGIZRg1jjbBiGUYM01bLGqPbDAegfeD0t2937HAAXPJOZQnYf8JYpvnnzzWnZ84vfB8DgUGYa++Trni/zz7dkQgOkjkIFgwWcO9XbgHx8Q2n61yIpm6ZY2XdnqMyZT9wekh28+X9CspV3vT8k+8rT4ehpn3/370Oy79yTV03DqDts5GwYhlGDNNXIOThizibocP7xCcsB+MJJZ6dl166YBcCZgRy5v93p/X20LzPCTnHz+SvT14tXvrMYdQ3DaGIKNs4icitwIbBDVU/wZROBRcAsYANwqara1rLRwMQ7xebyzBgc6nGWHRp2B8/PRYt0OeXjO492yt88sD4kS/njG7VLlGWN24DzsmQLgIdV9RjgYf+1kTAiskFEXhCRVZbE1TCai4IjZ1V9TERmZYkvBub517cDy4AvJ6hXokwccyKQ2fwrxKK9nn/zot+E3/tlYPATPGmYzfTTnk9fv2PDLO/ifyNVn817VfWNou5MmCldc0OyQe0f8dq1dNTWcnmk54s8EpIFfdJTTD/NYXfbEDQajGLXnKeq6lb/ehsQPk/rMzIdjWEYRnWIG8goNaiLw77+zbHvGRza4ZSXvCGoqioiOdPMBNPR5CuXNMFR3o6esOtVErhGdS6Of9s67+KZ+FUAv/btdrNvyzTW8RlG41Js47xdRKap6lYRmQa4m36jVM5Q1S0iMgVYKiJ/UNXHUm9Wq+MzDKP8FNs4LwEuBxb6f+9PTCMjjapu8f/uEJH7gLnAY/nvMqIgIhuAbrxI8oOqekq+8sogBwd3Ot6pfCD69rZDnXKXVwZAi2NvRFrczxg7anpItv/A2si6ichM4Md4S50K3KKq3438ACNNFFe6u/A2/yaLyGbgWrxGebGIXAFsBC4tp5JxOLzrTAD251jH8Qi6RJXnx9W9JpMJ5fDP+F6Gi6PfLyJdQIuqdvvX5wDfSFLHfKSCNQVZz5qQbEfvyCWjGWPnhcps3r8sUp1Rl4lav+AIIPX3n4h0bxY1s9naQAwCX1TVlSIyDnhGRJaqavPEzU2IKN4al+V466yEdTFGMhW4T0TA+3+6U1V/WV2VDCM/vqPAVv+6W0ReBqYD1jjHpM5PCHoj4DM6M65aT/b9BMjvZD9j7Jnp66ijurj8y5KMa/i//UdqczL66E5V1wPxt4uNqOTdbAXbcC0V3wX3ZGC5472AbeOlqGoW6rxxNoyiybvZCtkbri224RoDERmL531+jaruy34/aNsW6TDbOqibxnlq16kAnNE6Jy0b5Xe4d+6JFhRf/I9beLQs/t/ivzPXb70xff2tF1bmKZkM7S1jmdw5Z4Rsbssfh8od0h4+FNo7GP6coxyDmcf3/DYkk6yvkNu24pBFs20qm3mQgRduinRvPmyztXyISDtew3yHqt5bbX3qlbppnA0jKYrbbFWq4ZnhIl8ALxfDMcr2HAw3CUM6EPl+8TZJfgS8rKrfiVG1kYU1zkYzYput5eN04JPACyKyypd9VVUfqKJOdUmFG2dBaOOwrnelJW8fPg6AQ9ra07LU1HtgODP17Rvyrp8dygSoWL/vwVi1K4OFC/kl4xCcers2It/4Vm+s5xnlxTZby4eqPo57HcuIiY2cDcOoKsoABwe3VVuNEFEDpZWLijbO41omM3f0h1grmdHvphYvftKMwcPSsm2D3hrX8r47AndHW+9LbVBFHyWXTqHYuKvXpeLslm9jcDSdzNbZI2R7B8OHOlK2DbK878eR6sje/INodp405qSQbFfvsyHZrLHnhmQb9v8qJPvNXx0ekhlGo2FpqgzDMGoQW9YwDCPN4NAuh7Q2vFSajYo2zsM6TK8eZOP+h0LvRQ+tkp8kljMmjTkZcE+9U/7WAJ3iBY9xTb2DrHpjcsk6GYbRXNiyhmEYRg1S0ZFzj+7iqb7b+fiEz6VlLb7TzYr+jGP9xOHxAGxu3ZSWber1judHT0yZOeL2jjF/DsALvT/1JRlXucld7/RLZ1z5tvf8LvS0lLvc9OG3pmVvH+3p2dH1wbTsf/u9ewcC4SXPnuWHciwuTVUk2kU4bNTI0JAtDoem9X3hIwmfnfK5kGzHgXC5VUMbQrIuHTvi9VYJh60M2jatm+Pk37vb3xaSBW2bYvLY0Glgw2g4bORsGIZRg1jjbBiGUYNECbbvzGwgIhOBRcAsYANwqaruiVLpHXtuLFwI+OMxHw1cfxyA6WMyyxWpqXfvUGYK/ipeEsf1PZnTgy/0/iRnHW/0REvsl1pOWdl3Z1q2si/SrfQPhqf1Rn0xuW0KfzZhfkj+7P69zvLdLeHltwHcyQRGMdopnzQ8wSmfO95d/thD3V/IMa1hb4tnd491lITXHY/4VfciZ1mjvEQZOacyG8wGTgU+JyKzgQXAw6p6DPCw/9owDMNIgCiZUHJlNrgYL30VwO3AMuDLSSr3fG+mx34+dbE/yRoqwz89MyPneyJyK3AhsENVT/BlsWclu4d2RJ6RZPNExBlAFE7pDCcUWNH335HujRr69avLLf690fjEWnPOymww1W+4AbbhLXsY8bkNOC9LZrMSw2hyIrvSZWc28MMtAqCq6qf7cd1nqX7yoKqP+Z1ekLLPSgyjVpgzQ3jqCzH3ZYbjB76TrngnHfv+7C9i19E1ZV7se9pa3OnrIjXOOTIbbBeRaaq6VUSmAc501yNT/bgb8ErzjjEfSV+P0lFA9Kl3MSztuy3uLZFmJdbxVY4jpr7BDVf/KCSXthw/+DiNR5v7ZyGj3GHyZZJ7Q7D3PZc65V1TwrmYc2VtPrA+vHl+5iX9OUob5aTgskaezAZLgFRm1cuB+5NXz1BVJUeAaVW9RVVPUdVTKqyWYRhlJsrI2ZnZAFgILBaRK4CNgLvbrkHyudaVA1W3C1UeIs1KapFyzkBS/Lo3lCjbMBqOKN4a+TIbhOdLRhKkZiULsVmJUYeISCuwAtiiqhdWW596xE4IVhkRuQt4CjhWRDb7M5GFwPtFZA1wtv/aMOqJq4GXq61EPWPxnKuMqubam7FZiVGXiMgM4APAN4EvVFmdusUaZ6NhSeqAD8CONyZx480fDskPaQ+n/QIY3xH2cBhU90S1JYcT07C6VxP3DbjdzsZ3uPc2Dh21JCSbOdm9jbGvJ3ysu2+Ds2g+rge+BIRDD/oEPY2OcJ9Sb3psWcNoZG7DDvhUFBFJdYZ5g9YEPY0md1mybhfWOBsNi6o+BuzOEl+Md7AH/+8lFVWq8TkduEhENgB3A+8TkfK78DQg1jgbzUbksAMicqWIrBCRFT1DCQYgaWBU9SuqOkNVZwHzgUdU1X0EzsiLNc5G05LvgI//fnrq3dXaWUHNDMMaZ6P52O4f7KHeDvjUG6q6zHyci0e8wUOFKhPZCfQAb1Ss0vIwmeI+w5Gq+paklYG0bTf6L4vVr5aI+xmctvWDSv0i4K1xHbBLVReKyAJgoqp+qdDDA/ZtBNtGJfVZy/a9hdB311V/tahU/e7vbiUbZwARWVHvsSBq/TPUun5RSOIz+Ad85uH9yLYD1wI/AxYDR+CHHVDV7E3DsupVL1T7szZ7/ebnbDQsdsDHqGdszdkwDKMGqUbj3AghxWr9M9S6flGo1c9Qq3qVg2p/1qauv+JrzoZhGEZhbFnDMAyjBrHG2TAMowapaOMsIueJyCsistb3Ma15RGSmiDwqIi+JyGoRudqXTxSRpSKyxv9b9dha9Whf8KLHicgOEXkxIDP7Vohq27+QXUVklIgs8t9f7kiIXErdzt93Vpl5IrJXRFb5/76WVP15UdWK/ANagXXAW4EO4DlgdqXqL0HvacAc/3oc8CowG/g2sMCXLwD+tcp61qV9fd3fA8wBXgzIzL5NYP8odgWuAm7yr+cDixKs3/n7ziozD+8gU0X/Xyo5cp4LrFXV9eol1bsbL0JYTaOqW1V1pX/djZfdYTq1F92sLu0LdRM9rm7tW4gq2z+KXYO6/BQ4y088XTJ5ft9Vp6TGOeY0bzqwKfB6MzVihKj406mTgeXEiG5WIerevlmYfatLpewfxa7pMqo6COwFJiWtSNbvO5vTROQ5EXlQRI5Pum4XRTfOfgLHG4Hz8ab5l4nI7KQUqzVEZCxwD3CNqu4Lvqfe3Cdxn8RGXeOMS7nsa0SjGeyf7/cNrMSLf3EicANeCIDy6+SvqcS/UeQ04Ouqeq7/+isAqvqtPOWfLFLPRuENjRhAxu/8XgXejzeaeBq4TFVfylG+oX88EYhsW/A6PuC7eGueP1TVvEl0RVpUaC1RxZxPz1WnUz6s4RRYsWsUd6or1SFXjQCvquqxJVcc0kNOA3kytm2LWNWIW8ewHohfRw675kN1wPndLSW2hms68q7sQsFcYR7l+oLXA0OuyFu5SK/FAYhIai3O2Th7mG2jEJj1pTs+EVmSq+MD74fd1ja5dDVzPNtFW+top7y3f0PJdXa0HeaUHxwMx4BS7QOG7y+5UjdPF2PbliIawY7Wrljluw+siV9HDrvmo39gk/O7W/YNQQ0ELC93XQ1Gs61xVpKG3dwrI3lnFsXiryEbDkppnLcAMwOvZ/gyo0IE0yhVW5c6I1LHF7SvelP7pkXjhVW1vZIEKKVxfho4RkSOEpEOPP/DcA52o1gKdn42KykvQfuKHaaNRLM5CpSTor9x/nTk88Cv8HwDF6vq6qQUM6zzKyM26ysftmSUECUF21fVB4AHEtLFCKCqgyKS6vxagVut80uMdMeH1yjPBz6WZAWuTb5c3he5NqqK2ZCKSv/A6zFKx1rSKcJRwGYlLiwTSg1jnV95sI6v+qjqLfjxklukvdndQJ1Y42w0JdbxlQ1bMkoIm08YhpEktleSEDZyNkpixth5I15f9ZbwIbIf7HwlJNu8f5njaeF12tM6PxGS7WoJe3W92lORE7VGAWzJKDmscTYMI1FsySgZmqpxTo3ygqO7V/d5JnioP9O5b+t7AYDBoV0FnuiN9CaOOSEtOVZPAkaO7l7t+XnROhv1icszI5dXxrDGO+DirRaE8TzXjEahqRpnwzBqEJHYsTLixskAeKe8J1b5pfdHPhSZZvf942LfM/VWt9w2BA3DMGqQphg5//GYjwKwXb3gT1977afp9/5+mvfe92ZmokkNDHthFroHMr1532DYVJt6venl2u6Mm2b3oBdy8a+PyMQC/7+vnQnA6z3Liv8QNcDMse8LySYMj4x0uG8gvKn3vaPDkbp2938qJHPZ+NHt4RHVX08Ph4v8y5dDIsOoa2zkbBiGUYM07Mg5OMp7fv+inOVu2vUYAK/uOzMtG/IHwsHx2c5BL/D2oS2ZzZhNuhOANYNPpWUHDm4G4JKhK9KyrxzubUD+7ZplMT6BUQ/kWisdGOoOyXIdmZYcP8N5nVc45T+/xu02PPpU98bi7vvDsZIf/N2pzrKv94VjSN+45SfOskZ5sZGzYRhGDWKNs2EYRg3ScMsaU7u86dqm/Y9EKv9m34sA3Ov/TYpHto1KX//Lmc95F+ULMpY4k8acHJId1N6Q7PneRVmvHQ/bnJRWHjd88B1hoW0IGg2GjZwNwzBqkIYYOQdHeTt7X6iiJhnu6749ff298W+toiaGYdQjBRtnEbkVuBDYoaon+LKJwCJgFrABuFRV95RPTcOoLsogA4M7y/ZsF8/oY075B66/yCn/4tv3O+VDGvYLf2LnWGfZVfv3hWR7Bpo7f2K1iLKscRtwXpZsAfCwqh4DPOy/NhJGRDaIyAsissqSuBpGc1Fw5Kyqj4nIrCzxxcA8//p2YBnw5QT1isTEMScCsKv32dB7p3Venr4+cpR3Dv/nfb8CoKd/XSL1t7d5p+OumfqRtOzh3W8CsLLvzrTsN8+d6F+tKqaa96rqG0WqGImTxlwWkm3iDyHZU+eFR3gzLxh5IrD9iqFIdV4y7m9CsreNC4/wWsIifvNceHRXpG0No2Ypds15qqpu9a+3AVNzFRyZK8wwDGMkqgMxcxpC/0D8el7tCocRyMcDXz87dh2uJaTCvOSUlrwhqKoqIjlzgAVzheUrV4jUKaoTx2RGqa7RXYo7LsiEAJ15gTeyjjqqS9HSkokwdVGXF/Q9OLr73g7v5NR1W36Q9zk7+8OnriKiwK99u93s2zKNdXyG0bgU2zhvF5FpqrpVRKYBO5JUykhzhqpuEZEpwFIR+YNqZpcoqY7PMIzao9jGeQlwObDQ/3t/YhoZaVR1i/93h4jcB8wF3Fv4RixEZAPQDQwBg6p6SrV0ObzrTKd8W+9Kp/wx/ZFbHt56SYjoM04RmQn8GG+pU4FbVPW7ZVKsoYniSncX3ubfZBHZDFyL1ygvFpErgI3ApXEq7WjLrP1MHnUMAENkFpG6mADA3Paj0rKUN889+/IvIaQ4bklmDavnJ14063X/830ALvnlrPR7L/SGg7q0iLeBePiYd6Zl9+/3fhDanck2EVz2yMcRY90uTvkQkS6gRVW7/etzgG/kKj+hdQrnjvvoCNnB4fBgusOxw+bylFq1L/xLP27J4SFZyrYpejf/bajMsdeF270VGj7St2TbM2FFHNwz5QORykWg7JutTcgg8EVVXSki44BnRGSpqroXVo2cRPHWCG/le5yVsC7GSKYC94kIeP9Pd6rqL6urkmHkx3cU2Opfd4vIy8B0cu16GTmp6AnB8S1v4X1jPzpi9PbcgOf0cVxrZjS9YWAvAEv6Mjkie/s3xKoruPt7SOe1AGz6tOfWvfzLmWzQTz1wCQCfWp1xz9p2wDtl6M4QnWF42AsLGRxBp2RBlr4+KSQrhKquB04sWNAolrybrWAbrqXiu+CeDCx3vGe2LUBDHN82jCLIu9kKtuFaCiIyFrgHuEZVQ47pZtvCVLRxfnN4J/fu+48RsTCG1FtrfrnnvkjPKDRKdZEadU+6yXs9f/xV6ff+8TRvlLzsnANp2dvujXdMt5AeR4/z16m3x3psLPbpfpYefGqE7O1+JvAgG1v/NyS7qOv4kGzSYDgqneuwT1vL5SNerz4/vLm17Jywfd5279MhWVRe74mf3DMb22wtHyLSjtcw36Gq91Zbn3rFRs5G0xF3s7Xc7BnY6JQfNmaOUz6OiU75AelxyjfufygkG995grOsEt4d3n9grbOsC/E2SX4EvKyq34l8oxHCGmejGbHN1vJxOvBJ4AURSZ2p/6qqPpDnHsNBVRrn4PT49M5PA/BiZ6bHHtc6JXTPzKEjATj5kEw0rUXdT4aeF4W738y44933kOce9rXpH0zLBO95uaKFxWVUi0X1qiVss7V8qOrjjEy/aRSJjZwNw6gqR4+ZwHePOyfWPT9eGx7AFeLPj9wbq/z5//ZE7Dr23l1Ek5ojZlfVG+cn+v4LGJmBuL2rE4AumZCWPdV3u/832fpTLnf/sOHmZB8cYPXeomNrRGZouDc0g3iScOKBI8bOC8l+sP3GxPQ4/sHflnB3eMAljuzWo1rjxUgxjHrE0lQZhmHUIFUfORtGPZBr6v2bbe7p9UbHif3XDrq9KYL7KEH+dOqbTvlFH1nilLe+233Yae/dR4dk//nQ6c6y2/rCTcLdA2X0ATVyUjONc3Dz7Y0eL8ZC7Qc9SE3DMz70Ih2eRDMxOOZM9H+U9h03DCMitqxhGIZRg9TMyLnatLVmpoSDQ7si3hU+dRocMaf4x9fWFKtWSbhcAV0HEkoh5QqZ4skDd4TKtDqi97ltXNv2NIxKYiNnwzCMGsQaZ8MwjBokSrB9Z2YDEZkILAJmARuAS1V1T/lULZ5Upomjhr1d6+DUOzVtjr6UEZ+tPfGd2Y3aYuwx7Zzx62kh+Rm5bmjtDIladm9xF+3b4JQPdY53yg8e+imnvGuCO5nL6KPCsYc+d92hzrItu18JyX57UXhpySg/UUbOqcwGs4FTgc+JyGxgAfCwqh4DPOy/NmIiIreKyA4ReTEgmygiS0Vkjf93Qr5nGIbReETJhJIrs8HFeOmrAG4HlgFfLouWMUifNJRMv/N6j3dq7XVKOb3mUUzI0gLcBnwfb3aSItXxLRSRBf7r6tvWdxMMkjrhmY+osxJX2i+XjW0mYjQDsdacszIbTPUbboBteMseRkz8AO+7s8QX43V4+H8vqahShmFUnciudNmZDfxwiwCoqubKZmDpaIrCOj6jaci1np+PMxxr+oXIteafs/ysf4pdR8c7V8e+h//8llMcqXHOkdlgu4hMU9WtIjIN2OG6t9LpaNK+vWWqKaGljMhYx1cbdL86yLKzw1/xWW9xH/sc0xmO0DW684CjJOzvdh/fXrctvIwEsK/fve/e2vJrp/zkWWEdp5/kTvqyf3P4OPrwVrfeRnkpuKyRJ7PBEiCVo+hy4P7k1WtatvsdHoU6PlU9RVXd2/SGYdQtUdacU5kN3iciq/x/FwALgfeLyBrgbP+1kQw12fGpHgz9S5Lh4e7QP6M+EZFWEXlWRH5RbV3qlSjeGvkyG5yVrDrNh4jchef1MllENgPX4nV0i0XkCmAjcGn1NDSMorgaeBk4pNqK1CsWW6PKqOplOd6yjs+oS0RkBvAB4JvAF6qsTt1ix7cNw0ia64EvgSOVtxEZGzkbDYuI3ApcCOxQ1RN8WVFhB9b3dfORF34Tkre1ulOQdbSEPTBGOWQAvUPO/V76B9c55bnqHNPmDrY/cd3hIVn7Q9OdZfe1hE2xrXeTs6wLEUnZ+xkRmZenXNrTaOaM8OEjw0bORmNzG3BelszCDpSX04GLRGQDcDeeI8F/ZxcKehpNmhTfZ7kZsMbZaFjs9GXlUdWvqOoMVZ0FzAceUdVPVFmtusSWNYxmI/Lpy5GHfFrLrphhBLHG2Wha8p2+9N9Pn25tkY6yn25tNFR1GV5ANKMIbFnDaDYinb40jGojqpUbEIjITqCHekisnZ/JFPcZjlTVtyStDKRtu9F/Wax+tUTcz+C0rR9J8RcBb43rgF2BcKwTVfVLhR4esG8j2DYqqc9atu8thL67rvqrRaXqd393K9k4A4jIinqPBVHrn6HW9YtCEp8hePoS2I53+vJnwGLgCPzTl6qavWlYVr3qhWp/1mav39acjYbFTl8a9YytORuGYdQg1Wicb6lCnUlT65+h1vWLQq1+hlrVqxxU+7M2df0VX3M2DMMwCmPLGoZhGDWINc6GYRg1SEUbZxE5T0ReEZG1vo9pzSMiM0XkURF5SURWi8jVvnyiiCwVkTX+3wk1oGvd2Re86HEiskNEXgzIzL4Votr2L2RXERklIov895f7vutJ1e38fWeVmSciewOZoL6WVP15UdWK/MMLTrAOeCvQATwHzK5U/SXoPQ2Y41+PA14FZgPfBhb48gXAv1ZZz7q0r6/7e4A5wIsBmdm3Cewfxa7AVcBN/vV8YFGC9Tt/31ll5uEdZKro/0slR85zgbWqul695HN340UIq2lUdauqrvSvu/FS70yn9qKb1aV9oW6ix9WtfQtRZftHsWtQl58CZ/mJp0smz++76pTUOMec5k0HglG7N1MjRoiKP506GVhOjOhmFaLu7ZuF2be6VMr+UeyaLqOqg8BewJ1ZoASyft/ZnCYiz4nIgyJyfNJ1uyi6cRaRVuBG4Hy8af5lIjI7KcVqDREZC9wDXKOq+4LvqTf3SdwnsVHXOONSDvuabaNTru93LZHv9w2sxIt/cSJwA14IgPLr5K+pxL9R5DTg66p6rv/6KwCq+q085Z8sUs9G4Q2NGEDG7/xeBd6PN5p4GrhMVV/KUb6hfzwRKEa+dlkAABEsSURBVJttvXtaVCod7SDHxF11oLJ6eLyqqscm/VCvXZAnK2HbFolXx5D2lUmTEM7vbikWcU1H3pVdaGTAcmjuoOVDrshbuUivxQGISGotLmcDYraNTGzbCm20t00pTcWYiLgntv0Dr1dUDxgCuL9MD3+6UrbtbJ8Yq/zevjw/tURxf3fLviGogVxh5a6rwSi4FiciV4rIChFZUVHN6p9mWz9OgoXleKi/hmw4KKVx3gLMDLye4cuMCmEdX3kJdn7KcLXVqSoaL6yqrecnQCmN89PAMSJylIh04PkfLklGLQPr/MpJJNsGOz+xw7SRaDZHgXJS9Jqzqg6KyOeBX+Etdt6qqqsT08xId354Dcd84GPVVak4vjrjqpDsjw7pCck+9dLtIVmZaBjb1iBF7JUYLkraIlXVB4AHEtLFCGCdX/moNdvm2vgb3TbeKa/8hmAsinAUaOaN7NxYJhSfUe2Hp6+/ONU7DBUc3VVwVJfGOr/yYbatLmqZzQtiC2mGYSSJ7ZUkhDXOhmEkiTkKJERTLmtM6Zqbvr5vzmQAdvWMTcsuWvkDAPb87RFp2cB1XmiBW/7uwrTs6V2jAVjZl8mevm7Icznu6V+XtNp1wRNnXhCS7eoJZ5c//59/E5J9fNARLuGNN0OiB2/8UEh20cq7ImpolJNaW8+vZ5qycTYMo3zYen4yNGXjvKPn9+nr03/r/f3UpM+Fyk244bX0de/kQwC48rpMzJMr+/yz9z39adnAJm8E/tCSS9Oyv3plg1/vU6UpbtQ1ubwyhnPEyuhqcQde25vj+bPGnuuUTxwKP+e40e7Y+Tv6w7r87sBPc9RolJOmbJwNw6hvcnV0+cjV2eViQo7OLh+ntx8d+5479nzPKbcNQcMwjBrERs4+t+26MX39l5O9JY5b38jIxlybHeLVzXs7PwLAP83Zlpb980wvNvdn/tB4yxqnd3565Ovf/leoTMqeQT5zaXiEsbXniZDsvZ1/FZLd+N4/xFHRMOoSGzkbhmHUIE01ck6N8p7oC4/ugjze520ETus6PS1zjepcPNr3QwCOW5sZLX7+nc95Fzbgq2MU9eIaj0ByHD12lR0c7HaWHdZwnBGA1wd3xtAvNy8OPBKSPXsg7KIIcNiYd4ZkB6hY0HkjgI2cDcMwahBrnA3DMGqQpljWSC1PPNGTeznjyLFnp6/78KaZu/v/Ny1raRkHwPCwe2qazfa+TCyXn72cStYbPhVXTxzblZ2xHrazo+B9/eEZPj1D4VODHxz72ZBs4/CekGz99mkF6zSMesdGzoZhGDVIwZGziNwKXAjsUNUTfNlEYBEwC9gAXKqq4SFOFQmO8oYonKbsgO5PX5/d4W2K/HwwE0wrlbn37I6Pp2Vbhjz3ukHJDA2f710EwKmTM3UeN8E3TWYgbhiGkZcoyxq3Ad8HfhyQLQAeVtWFfo6wBcCXk1fPMGoDZZCBhLwnSkec0k29v3PKh4ZzHfgO4/ZKcqxLGWWn4LKGqj4GZCd3vBhIRZ+/HbgkYb0MQEQ2iMgLIrLKMmwbRnNR7IbgVFXd6l9vA6YmpE9RdLQdlr7+6nSvn7h3Z2aVJbXUkI/tPZlRx529qwBobelMy4aGvI3AR2RpWpYvLOhR4zIbh+f+nR/O9hMF1XDxXlUN7545yR5RFZ9g4oKuz4RkcyeHR2xf33hTwWfd+eaPQrKgbVM8oktDMpeN37/8lnAlbXcX1MMw6omSvTVUVUUkZyswMleYYRjGSJQBDg5uK1ywRF6PmXuxteXQ2HX8cnRh76WoFNs4bxeRaaq6VUSmQW5/qmCusEwjHhyBFT+6O2T0sQCc0TovLfv6xptLfq7qAQAGhw6E3osaRP/AUMa0w/Nv8C4+cUVsVYBf+3a72bdlGuv4DKNxKdaVbglwuX99OXB/MuoYWZyhqnOA84HPich7gm+q6i2qeoqqnlId9eoXW88vDyIyU0QeFZGXRGS1iFxdbZ3qlSiudHcB84DJIrIZuBZYCCwWkSuAjcCluZ9gFIuqbvH/7hCR+4C5wGPV1aqhiLGeXzu0yBinfHjYHaNDZHRINrHzOGfZ43VOSLbywL0xtGMQ+KKqrhSRccAzIrJUVV+K8xAjQuOsqpfleOus4qstfsmhsyOT129Kqxd28oGem3MVrxr3vpbJSTi/ZVTs+0WkC2hR1W7/+hzgG7nKT2qdwgfHzx8hmzspvCzz5kD4v/z0aeG1uCue2xySLd9ZeM0umJ8xRTDzTArXktHgUDRX+dYi7GlUBt9RYKt/3S0iLwPTAWucY9IUx7frlKnAfSIC3v/Tnar6y+qq1FDkXc83SkdEZgEnA8urq0l9UtHGWaSdjrbDuOyQP0vLUqO7rX0dadneAW8p/LDOzCm71Ojup+szI+cbtmWC4WczaczJ6etdvc+OeG/c6GPS152tXi411+iuFO7d9x/p6+EiloRVdT1wYoIqGSM5Q1W3iMgUYKmI/MH36U9jG67FIyJjgXuAa1Q1lKnCbFsYi61hNCXB9XwgtZ6fXcY2XItARNrxGuY7VNW5YG22LUxFR85v6xzL9cedzsKXMsG7Hz+wHYCLDz0yLZs19iAAD2/LBDL/xhZv9Hvg4M8j1ZU9Wg7SfWBN5jrS00qjf1P5s8RPGDXAh2eN9Gh8dOtbQuWmjwlnVz53RdhWBw6G15yjkPQMxEXfa0tKuj/uer4RHfHW4X4EvKyq36m2PvWMrTkbzUhNrecf2jnbKR8c7nfKo/rap9Fw4K/dfaudRV/rmhKSHZSDcWo7Hfgk8IKIrPJlX1XV8o9QGgxrnI2mw9bzy4eqPk6uyExGLCraOK/t3cOFz/zE+d6/u100G4LRy+yMjmEY8bCRs2EYVaVFRtHZcWThggFcCXQL0d7iPryTi7198V2zcy0XFUNVGud3df5F+vr6P/Fi5P7NivFp2areu4p+dteotwFFrMsVIJXqKmoW7iB9H/qqd/Gpa5NUaQRb+1r455dGRnq7/k/C0f3PfCIc8zfq4Y+UbYMUa+dgZvMUUW2rk44vXMgw6hxzpTMMw6hBbFnDMCKQa+qda+bQIl0h2eiOsGsjwMGh/U5538HXYmgYD1W3B8aG/b9ySC0TSjWoSuP8TMBX+bvPe6E7Pjkt4+7z4gbv1F7U6XaQpJcz0s91ZIuOyu4rovlmG4ZhpLBlDcMwjBqkKiPnoeHMCcG73/wBAL8bPDct+8zkjwGwfF8mMeWmlrUADGjm3j19rwCZ4PjlZN+BV4q+996VqROq5Qsb3KN7+P2BxSNkl63801C5lG2D7OoPRwl8YvAPIdmm/Y+UoOFIitlYTfHDk7cWLmQYdY6NnA3DMGoQa5wNwzBqkCiZUGYCP8aLR6DALar6XRGZCCwCZgEbgEtVNdIOnmsZ4rXeJ9PX63QWACeMySRYPGrQy9DQGjgY+kTLJCDZ6XY5+OK6/1dtFYwSOXpMJze944SQ/Hurz3GWf/BA+FRoX787mJQSjn0B0N7m9u6YPOqPnPKTCesH0K/DIdlGcSdOOFZmhmSP9y52lDTKTZSRcyrtzGzgVLxcdrOBBcDDqnoM8LD/2oiJiNwqIjtE5MWAbKKILBWRNf7fCdXU0TCMyhMlTVWutDMX4+UWBLgdWAZ8uVhFhoczwTt/mUo7FYi3kfIbPa7zvLRsc9/jxVZXUQpsWN4GfB9vdpIi1fEtFJEF/usCth0O1ePyWb3RITt+zIdCslq27YIN5ppoND6x1pyz0s5M9RtugG14yx6ue64UkRWW4diNn31jd5b4YrwOD//vJRVVyjCMqhPZlS477YwfCxcAVVU/F1sIPzfbLf4zis/s2lxE6vgMoxE4ec7hLH/6a7Hu2fEX345dz9494wsXCnD0VUX87IbD6/uFaP9gn1MeqXHOkXZmu4hMU9WtIjIN2JH7CaUzrN4ax+ree8pZTVnoaDsMgIODW2Lfm6/jszxslWPc2yfwnif/PCQ/82f/x1l+570zQrKX14QzkwO0tLh/0IdN3OWUz3r3Kqe87aS1TrmrwdDXsidrHge3hBuwM2+Nf1LXKJ2Cyxp50s4sAS73ry8HLGhxcmz3OzzydXyWh80wGpcoI2dn2hlgIbBYRK4ANgKXlkfF5JjadSoAn54wJy1buPkHZalrfGfGralV2gHYFX3knOr4FlKBji/qbMTl2jUxK4xo0LYpkrbxuI5pIVkM2xoVQERa8Y7EblHVC6utTz0SxVsjX9qZs5JVp/kQkbvwvF4mi8hm4FrqsOMzjCyuBl4GDqm2IvWKhQytMqp6WY63rOMz6hIRmQF8APgm8IUqq1O3NFzjnJp6DwzuDL23vcfLArKwJ5wNJGne7HuxcCHDaEyuB74EjMtVILiZfcQRkyqkVn3RcI2zYaQQkVuBC4EdqnqCLysq7ED/uh289pEbQvLpZ/Y6y0/44tiQ7F1j3YeROl4LRwDMx+DjrU757nvcrmIdXWFXra6j3SuVA93hJAE6/GZk3UQkZe9nRGRernJBF9tTTnmrudg6aLjG2TViNpLBORvJklViVrKr99moRW8jkdOXRgxOBy4SkQuA0cAhIvLfqvqJKutVd1hUOqNhsdOXlUdVv6KqM1R1FjAfeMQa5uKwxtloNiKfvgyGHtjdP1AZ7QzDxxpno2lRVcULg5vr/fQhn4mj2iuoWWOgqsvMx7l4rHE2mo1Ipy8No9qIN3ioUGUiO/ECgRafyro2mExxn+FIVXVHUC8R37Yb/ZfF6ldLxP0MTtv6kRR/EfDWuA7YFdgQnKiqXyr08IB9G8G2UUl91rJ9byH03XXVXy0qVb/7u1vJxhlARFbUeyyIWv8Mta5fFJL4DMHTl8B2vNOXPwMWA0fgn75UVXcUoDLpVS9U+7M2e/0N50pnGCns9KVRz9ias2EYRg1Sjcb5lirUmTS1/hlqXb8o1OpnqFW9ykG1P2tT11/xNWfDMAyjMLasYRiGUYNUtHEWkfNE5BURWeu7MdU8IjJTRB4VkZdEZLWIXO3LJ4rIUhFZ4/+dUAO61p19wQtQJCI7ROTFgMzsWyGqbf9CdhWRUSKyyH9/ue8emVTdzt93Vpl5IrJXRFb5/+IlPCwWVa3IP6AVWAe8FegAngNmV6r+EvSeBszxr8cBrwKzgW8DC3z5AuBfq6xnXdrX1/09wBzgxYDM7NsE9o9iV+Aq4Cb/ej6wKMH6nb/vrDLz8HzlK/r/UsmR81xgraquV9WDwN14QWhqGlXdqqor/etuvOwO06m9ADp1aV+omwBFdWvfQlTZ/lHsGtTlp8BZfm7Tksnz+646lWycpwObAq83UyNGiIo/nToZWE6MADoVou7tm4XZt7pUyv5R7Jouo6qDwF4g8Qj9Wb/vbE4TkedE5EEROT7pul3YIZSIiMhY4B7gGlXdF+y4VVVFxNxeyoTZt7o0g/2zf99Zb6/EO2K9349T/TPgmHLrVMmR8xZgZuD1DF9W84hIO95/3B2qeq8vrrUAOnVr3xyYfatLpewfxa7pMiLSBhwK7EpKgRy/7zSquk9V9/vXDwDtIjI5qfpzUcnG+WngGBE5SkQ68Bb2l1Sw/qLw17Z+BLysqt8JvLUEuNy/vhy4v9K6ZVGX9s2D2be6VMr+Uewa1OXDeAH8ExnJ5/l9B8scllrjFpG5eO1mYp1DTiq5+whcgLcbug74h0rvfhap8xl4MX+fB1b5/y7AW/N6GFgDPIQX3azautadfX297wK2AgN4a45XmH2bx/4uuwLfAC7yr0cDPwHWAr8H3ppg3bl+358FPuuX+TywGs+T5HfAuyvx/2InBA3DMGoQOyFoGIZRg1jjbBiGUYNY42wYhlGDWONsGIZRg1jjbBiGUYNY42wYhlGDWONsGIZRg1jjbBiGUYP8fzDaF3fUkPw2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Improving the Fashion classifier with convolutions 看到 2:34！！！'''\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(3,4)\n",
    "FIRST_IMAGE = 0\n",
    "SECOND_IMAGE = 23\n",
    "THIRD_IMAGE = 28\n",
    "CONVOLUTION_NUMBER = 1\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "    f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1,28,28,1))[x]\n",
    "    axarr[0,x].imshow(f1[0,:,:,CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[0,x].grid(False)\n",
    "    f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1,28,28,1))[x]\n",
    "    axarr[1,x].imshow(f2[0,:,:,CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[1,x].grid(False)\n",
    "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
